{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22a0d244",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import wordpunct_tokenize\n",
    "import re\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "vectorizer = TfidfVectorizer(max_features = 2000)\n",
    "naive_bayes_classifier = MultinomialNB()\n",
    "\n",
    "stopword_english = list(stopwords.words(\"english\"))\n",
    "\n",
    "with open(\"Franck-Dernoncourt pubmed-rct master PubMed_200k_RCT/train.txt\",\"r\") as f:\n",
    "    data_train = f.readlines()\n",
    "\n",
    "with open(\"Franck-Dernoncourt pubmed-rct master PubMed_200k_RCT/dev.txt\",\"r\") as f:\n",
    "    data_dev = f.readlines()\n",
    "\n",
    "with open(\"Franck-Dernoncourt pubmed-rct master PubMed_200k_RCT/test.txt\",\"r\") as f:\n",
    "    data_test = f.readlines()\n",
    "\n",
    "def clean(sentence, stopword_english= stopword_english):\n",
    "    sentence = sentence.lower()\n",
    "#     sentence = re.sub(r'[^\\w\\s]',\"\",sentence) ##Removes punc from within words\n",
    "    words = wordpunct_tokenize(sentence)\n",
    "    punc = '''!()-[]{};:'\"\\,<>./?@#$%^&*_~'''\n",
    "    sentence = [x for x in words if x not in stopword_english]\n",
    "    sentence = [x for x in sentence if x not in punc] #Removes punc and seperates words\n",
    "    return \" \".join(sentence)\n",
    "\n",
    "def get_clean_data(sentences):\n",
    "    labels = []\n",
    "    clean_sentences = []\n",
    "    for line in sentences:\n",
    "        line = line.rstrip(\"\\n\")\n",
    "        a = line.split(\"\\t\")\n",
    "        if len(a)<2:\n",
    "            continue\n",
    "        label = a[0]\n",
    "        sentence = a[1]\n",
    "        sent= clean(sentence)\n",
    "        labels.append(label)\n",
    "        clean_sentences.append(sent)\n",
    "    return clean_sentences, labels\n",
    "\n",
    "X_train, Y_train = get_clean_data(data_train)\n",
    "X_dev, Y_dev = get_clean_data(data_dev)\n",
    "X_test, Y_test = get_clean_data(data_test)\n",
    "\n",
    "X_train_tf_idf = vectorizer.fit_transform(X_train)\n",
    "X_dev_tf_idf = vectorizer.transform(X_dev)\n",
    "X_test_tf_idf = vectorizer.transform(X_test)\n",
    "\n",
    "unq, counts = np.unique(Y_train, return_counts=True)\n",
    "diction = {}\n",
    "for x in unq:\n",
    "    diction[x] = len(diction)\n",
    "reverse_diction = {v:x for x,v in diction.items()}\n",
    "\n",
    "counts = sum(counts)/counts\n",
    "counts = counts/np.min(counts)\n",
    "\n",
    "\n",
    "def numerize(Y, diction= diction):\n",
    "    return [diction[x] for x in Y]\n",
    "Y_train_num = numerize(Y_train, diction)\n",
    "Y_dev_num = numerize(Y_dev, diction)\n",
    "Y_test_num = numerize(Y_test, diction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a6cd222e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import optimizers, losses, activations, models, Sequential\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, LearningRateScheduler, ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Dense, Input, Dropout, Convolution1D, MaxPool1D, GlobalMaxPool1D, GlobalAveragePooling1D, \\\n",
    "    concatenate, SimpleRNN, LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af21f987",
   "metadata": {},
   "outputs": [],
   "source": [
    "from model_arch import baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f6718b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-09 02:33:50.133590: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 02:33:50.162856: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 02:33:50.163519: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 02:33:50.185668: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-04-09 02:33:50.186269: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 02:33:50.186555: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 02:33:50.186770: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 02:33:50.682740: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 02:33:50.683162: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 02:33:50.683378: I tensorflow/stream_executor/cuda/cuda_gpu_executor.cc:939] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero\n",
      "2022-04-09 02:33:50.683670: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1525] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 172 MB memory:  -> device: 0, name: NVIDIA GeForce GTX 1060, pci bus id: 0000:01:00.0, compute capability: 6.1\n",
      "2022-04-09 02:33:50.687051: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 172.94M (181338112 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 02:33:50.687359: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 155.64M (163204352 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 02:33:50.687700: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 140.08M (146884096 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 02:33:50.691161: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 46.87M (49142272 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 02:33:50.691518: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 46.87M (49142272 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 02:34:00.692054: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 46.87M (49142272 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 02:34:00.692505: I tensorflow/stream_executor/cuda/cuda_driver.cc:739] failed to allocate 46.87M (49142272 bytes) from device: CUDA_ERROR_OUT_OF_MEMORY: out of memory\n",
      "2022-04-09 02:34:00.692540: W tensorflow/core/common_runtime/bfc_allocator.cc:462] Allocator (GPU_0_bfc) ran out of memory trying to allocate 44.11MiB (rounded to 46252032)requested by op AddV2\n",
      "If the cause is memory fragmentation maybe the environment variable 'TF_GPU_ALLOCATOR=cuda_malloc_async' will improve the situation. \n",
      "Current allocation summary follows.\n",
      "Current allocation summary follows.\n",
      "2022-04-09 02:34:00.692548: I tensorflow/core/common_runtime/bfc_allocator.cc:1010] BFCAllocator dump for GPU_0_bfc\n",
      "2022-04-09 02:34:00.692556: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (256): \tTotal Chunks: 3, Chunks in use: 2. 768B allocated for chunks. 512B in use in bin. 8B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692562: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (512): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692570: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1024): \tTotal Chunks: 1, Chunks in use: 1. 1.2KiB allocated for chunks. 1.2KiB in use in bin. 1.0KiB client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692576: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2048): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692582: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4096): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692588: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8192): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692595: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16384): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692602: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (32768): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692608: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (65536): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692614: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (131072): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692619: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (262144): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692624: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (524288): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692629: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (1048576): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692633: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (2097152): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692638: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (4194304): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692643: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (8388608): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692648: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (16777216): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692657: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (33554432): \tTotal Chunks: 1, Chunks in use: 1. 44.11MiB allocated for chunks. 44.11MiB in use in bin. 44.11MiB client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692663: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (67108864): \tTotal Chunks: 1, Chunks in use: 1. 81.96MiB allocated for chunks. 81.96MiB in use in bin. 44.11MiB client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692668: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (134217728): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692673: I tensorflow/core/common_runtime/bfc_allocator.cc:1017] Bin (268435456): \tTotal Chunks: 0, Chunks in use: 0. 0B allocated for chunks. 0B in use in bin. 0B client-requested in use in bin.\n",
      "2022-04-09 02:34:00.692679: I tensorflow/core/common_runtime/bfc_allocator.cc:1033] Bin for 44.11MiB was 32.00MiB, Chunk State: \n",
      "2022-04-09 02:34:00.692683: I tensorflow/core/common_runtime/bfc_allocator.cc:1046] Next region of size 132195840\n",
      "2022-04-09 02:34:00.692691: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f71f8000000 of size 1280 next 1\n",
      "2022-04-09 02:34:00.692696: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f71f8000500 of size 256 next 2\n",
      "2022-04-09 02:34:00.692700: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f71f8000600 of size 256 next 3\n",
      "2022-04-09 02:34:00.692704: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f71f8000700 of size 46252032 next 4\n",
      "2022-04-09 02:34:00.692708: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] Free  at 7f71fac1c700 of size 256 next 5\n",
      "2022-04-09 02:34:00.692712: I tensorflow/core/common_runtime/bfc_allocator.cc:1066] InUse at 7f71fac1c800 of size 85941760 next 18446744073709551615\n",
      "2022-04-09 02:34:00.692716: I tensorflow/core/common_runtime/bfc_allocator.cc:1071]      Summary of in-use Chunks by size: \n",
      "2022-04-09 02:34:00.692721: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 2 Chunks of size 256 totalling 512B\n",
      "2022-04-09 02:34:00.692726: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 1280 totalling 1.2KiB\n",
      "2022-04-09 02:34:00.692731: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 46252032 totalling 44.11MiB\n",
      "2022-04-09 02:34:00.692736: I tensorflow/core/common_runtime/bfc_allocator.cc:1074] 1 Chunks of size 85941760 totalling 81.96MiB\n",
      "2022-04-09 02:34:00.692741: I tensorflow/core/common_runtime/bfc_allocator.cc:1078] Sum Total of in-use chunks: 126.07MiB\n",
      "2022-04-09 02:34:00.692745: I tensorflow/core/common_runtime/bfc_allocator.cc:1080] total_region_allocated_bytes_: 132195840 memory_limit_: 181338112 available bytes: 49142272 curr_region_allocation_bytes_: 362676224\n",
      "2022-04-09 02:34:00.692753: I tensorflow/core/common_runtime/bfc_allocator.cc:1086] Stats: \n",
      "Limit:                       181338112\n",
      "InUse:                       132195584\n",
      "MaxInUse:                    132195840\n",
      "NumAllocs:                           6\n",
      "MaxAllocSize:                 85941760\n",
      "Reserved:                            0\n",
      "PeakReserved:                        0\n",
      "LargestFreeBlock:                    0\n",
      "\n",
      "2022-04-09 02:34:00.692758: W tensorflow/core/common_runtime/bfc_allocator.cc:474] **********************************************************************xxxxxxxxxxxxxxxxxxxxxxxxxxxxxx\n",
      "2022-04-09 02:34:00.817507: W tensorflow/core/framework/op_kernel.cc:1733] RESOURCE_EXHAUSTED: failed to allocate memory\n"
     ]
    },
    {
     "ename": "ResourceExhaustedError",
     "evalue": "failed to allocate memory [Op:AddV2]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)",
      "\u001b[1;32m/home/arka/Desktop/ML4H/ML4HC_Projects/Task2/Task2.ipynb Cell 4'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/arka/Desktop/ML4H/ML4HC_Projects/Task2/Task2.ipynb#ch0000025?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m baseline(nclass\u001b[39m=\u001b[39;49m\u001b[39m5\u001b[39;49m, shape\u001b[39m=\u001b[39;49mX_train_tf_idf\u001b[39m.\u001b[39;49mshape[\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m])\n",
      "File \u001b[0;32m~/Desktop/ML4H/ML4HC_Projects/Task2/model_arch.py:9\u001b[0m, in \u001b[0;36mbaseline\u001b[0;34m(nclass, shape)\u001b[0m\n\u001b[1;32m      <a href='file:///home/arka/Desktop/ML4H/ML4HC_Projects/Task2/model_arch.py?line=6'>7</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbaseline\u001b[39m(nclass\u001b[39m=\u001b[39m \u001b[39m5\u001b[39m, shape \u001b[39m=\u001b[39m \u001b[39m100\u001b[39m):\n\u001b[1;32m      <a href='file:///home/arka/Desktop/ML4H/ML4HC_Projects/Task2/model_arch.py?line=7'>8</a>\u001b[0m     inp \u001b[39m=\u001b[39m Input(shape\u001b[39m=\u001b[39m(shape))\n\u001b[0;32m----> <a href='file:///home/arka/Desktop/ML4H/ML4HC_Projects/Task2/model_arch.py?line=8'>9</a>\u001b[0m     dense_1 \u001b[39m=\u001b[39m Dense(\u001b[39m64\u001b[39;49m, activation\u001b[39m=\u001b[39;49mactivations\u001b[39m.\u001b[39;49mrelu, name\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mdense_1\u001b[39;49m\u001b[39m\"\u001b[39;49m)(inp)\n\u001b[1;32m     <a href='file:///home/arka/Desktop/ML4H/ML4HC_Projects/Task2/model_arch.py?line=9'>10</a>\u001b[0m     dense_1 \u001b[39m=\u001b[39m Dense(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39mactivations\u001b[39m.\u001b[39mrelu, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mdense_2\u001b[39m\u001b[39m\"\u001b[39m)(dense_1)\n\u001b[1;32m     <a href='file:///home/arka/Desktop/ML4H/ML4HC_Projects/Task2/model_arch.py?line=10'>11</a>\u001b[0m     dense_1 \u001b[39m=\u001b[39m Dense(nclass, activation\u001b[39m=\u001b[39mactivations\u001b[39m.\u001b[39msoftmax)(dense_1)\n",
      "File \u001b[0;32m~/.conda/envs/NLP/lib/python3.10/site-packages/keras/utils/traceback_utils.py:67\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=64'>65</a>\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=65'>66</a>\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[0;32m---> <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=66'>67</a>\u001b[0m   \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=67'>68</a>\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/utils/traceback_utils.py?line=68'>69</a>\u001b[0m   \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.conda/envs/NLP/lib/python3.10/site-packages/keras/backend.py:1831\u001b[0m, in \u001b[0;36mRandomGenerator.random_uniform\u001b[0;34m(self, shape, minval, maxval, dtype)\u001b[0m\n\u001b[1;32m   <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/backend.py?line=1827'>1828</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generator:\n\u001b[1;32m   <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/backend.py?line=1828'>1829</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_generator\u001b[39m.\u001b[39muniform(\n\u001b[1;32m   <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/backend.py?line=1829'>1830</a>\u001b[0m       shape\u001b[39m=\u001b[39mshape, minval\u001b[39m=\u001b[39mminval, maxval\u001b[39m=\u001b[39mmaxval, dtype\u001b[39m=\u001b[39mdtype)\n\u001b[0;32m-> <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/backend.py?line=1830'>1831</a>\u001b[0m \u001b[39mreturn\u001b[39;00m tf\u001b[39m.\u001b[39;49mrandom\u001b[39m.\u001b[39;49muniform(\n\u001b[1;32m   <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/backend.py?line=1831'>1832</a>\u001b[0m     shape\u001b[39m=\u001b[39;49mshape, minval\u001b[39m=\u001b[39;49mminval, maxval\u001b[39m=\u001b[39;49mmaxval, dtype\u001b[39m=\u001b[39;49mdtype,\n\u001b[1;32m   <a href='file:///home/arka/.conda/envs/NLP/lib/python3.10/site-packages/keras/backend.py?line=1832'>1833</a>\u001b[0m     seed\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmake_legacy_seed())\n",
      "\u001b[0;31mResourceExhaustedError\u001b[0m: failed to allocate memory [Op:AddV2]"
     ]
    }
   ],
   "source": [
    "model = baseline(nclass=5, shape=X_train_tf_idf.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9318599a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2211861, 180672)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6a9ada4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "4f1ef7aa5dc8ea708e49c3e0ba9400d5fdd1a5157cd9f50ad54cf12215c7de3f"
  },
  "kernelspec": {
   "display_name": "NLP",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
